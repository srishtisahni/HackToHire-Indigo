{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk rouge-score scikit-learn torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWp7IWNNpj1C",
        "outputId": "dfaf6658-c6b2-4300-d203-e71a40ec017e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=04031116c563c741ab9126d0e86bc4e24e7d3a45568c192a0f79207e821579c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, rouge-score, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8-oiIbu9OuMR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge_score import rouge_scorer\n",
        "from sklearn.metrics import f1_score\n",
        "from Datatests import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlvneWZTPKPM",
        "outputId": "f2455ffe-b973-4546-809b-eb0e9df5911e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/gdrive/My Drive/Indigo-HackToHire/processed_data.csv', index_col=0)\n",
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "IP7NepArPiLP",
        "outputId": "82b75086-e428-4f01-8a7c-949f5eeeec98"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question  \\\n",
              "0  Why whenever I get in the shower my girlfriend...   \n",
              "1            What is a proxy, and how can I use one?   \n",
              "2  What song has the lyrics \"someone left the cak...   \n",
              "3  I am the owner of an adult website called http...   \n",
              "4  Does the Bible mention anything about a place ...   \n",
              "\n",
              "                                  tokenized_question  \\\n",
              "0  ['why', 'whenever', 'i', 'get', 'in', 'the', '...   \n",
              "1  ['what', 'is', 'a', 'proxy', 'and', 'how', 'ca...   \n",
              "2  ['what', 'song', 'has', 'the', 'lyrics', 'some...   \n",
              "3  ['i', 'am', 'the', 'owner', 'of', 'an', 'adult...   \n",
              "4  ['does', 'the', 'bible', 'mention', 'anything'...   \n",
              "\n",
              "                                    stemmed_question  \\\n",
              "0  ['whi', 'whenev', 'i', 'get', 'in', 'the', 'sh...   \n",
              "1  ['what', 'is', 'a', 'proxi', 'and', 'how', 'ca...   \n",
              "2  ['what', 'song', 'ha', 'the', 'lyric', 'someon...   \n",
              "3  ['i', 'am', 'the', 'owner', 'of', 'an', 'adult...   \n",
              "4  ['doe', 'the', 'bibl', 'mention', 'anyth', 'ab...   \n",
              "\n",
              "                               setmmed_nostop_answer  \\\n",
              "0  ['whi', 'whenev', 'get', 'shower', 'girlfriend...   \n",
              "1                            ['proxi', 'use', 'one']   \n",
              "2  ['song', 'ha', 'lyric', 'someon', 'left', 'cak...   \n",
              "3  ['owner', 'adult', 'websit', 'call', 'http', '...   \n",
              "4  ['doe', 'bibl', 'mention', 'anyth', 'place', '...   \n",
              "\n",
              "                                              answer  \\\n",
              "0  Isn’t it awful? You would swear that there was...   \n",
              "1  A proxy server is a system or router that prov...   \n",
              "2                                 MacArthur's Park\\n   \n",
              "3  Don't let apps that are liers put adds on your...   \n",
              "4  St. John in the book of Revelation mentions an...   \n",
              "\n",
              "                                    tokenized_answer  \\\n",
              "0  ['isn’t', 'it', 'awful', 'you', 'would', 'swea...   \n",
              "1  ['a', 'proxy', 'server', 'is', 'a', 'system', ...   \n",
              "2                         ['macarthur', 's', 'park']   \n",
              "3  ['don', 't', 'let', 'apps', 'that', 'are', 'li...   \n",
              "4  ['st', 'john', 'in', 'the', 'book', 'of', 'rev...   \n",
              "\n",
              "                                      stemmed_answer  \n",
              "0  ['isn’t', 'it', 'aw', 'you', 'would', 'swear',...  \n",
              "1  ['a', 'proxi', 'server', 'is', 'a', 'system', ...  \n",
              "2                         ['macarthur', 's', 'park']  \n",
              "3  ['don', 't', 'let', 'app', 'that', 'are', 'lie...  \n",
              "4  ['st', 'john', 'in', 'the', 'book', 'of', 'rev...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2fa7c73f-c30d-4d9b-bd6d-defa841a034e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>tokenized_question</th>\n",
              "      <th>stemmed_question</th>\n",
              "      <th>setmmed_nostop_answer</th>\n",
              "      <th>answer</th>\n",
              "      <th>tokenized_answer</th>\n",
              "      <th>stemmed_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Why whenever I get in the shower my girlfriend...</td>\n",
              "      <td>['why', 'whenever', 'i', 'get', 'in', 'the', '...</td>\n",
              "      <td>['whi', 'whenev', 'i', 'get', 'in', 'the', 'sh...</td>\n",
              "      <td>['whi', 'whenev', 'get', 'shower', 'girlfriend...</td>\n",
              "      <td>Isn’t it awful? You would swear that there was...</td>\n",
              "      <td>['isn’t', 'it', 'awful', 'you', 'would', 'swea...</td>\n",
              "      <td>['isn’t', 'it', 'aw', 'you', 'would', 'swear',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is a proxy, and how can I use one?</td>\n",
              "      <td>['what', 'is', 'a', 'proxy', 'and', 'how', 'ca...</td>\n",
              "      <td>['what', 'is', 'a', 'proxi', 'and', 'how', 'ca...</td>\n",
              "      <td>['proxi', 'use', 'one']</td>\n",
              "      <td>A proxy server is a system or router that prov...</td>\n",
              "      <td>['a', 'proxy', 'server', 'is', 'a', 'system', ...</td>\n",
              "      <td>['a', 'proxi', 'server', 'is', 'a', 'system', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What song has the lyrics \"someone left the cak...</td>\n",
              "      <td>['what', 'song', 'has', 'the', 'lyrics', 'some...</td>\n",
              "      <td>['what', 'song', 'ha', 'the', 'lyric', 'someon...</td>\n",
              "      <td>['song', 'ha', 'lyric', 'someon', 'left', 'cak...</td>\n",
              "      <td>MacArthur's Park\\n</td>\n",
              "      <td>['macarthur', 's', 'park']</td>\n",
              "      <td>['macarthur', 's', 'park']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I am the owner of an adult website called http...</td>\n",
              "      <td>['i', 'am', 'the', 'owner', 'of', 'an', 'adult...</td>\n",
              "      <td>['i', 'am', 'the', 'owner', 'of', 'an', 'adult...</td>\n",
              "      <td>['owner', 'adult', 'websit', 'call', 'http', '...</td>\n",
              "      <td>Don't let apps that are liers put adds on your...</td>\n",
              "      <td>['don', 't', 'let', 'apps', 'that', 'are', 'li...</td>\n",
              "      <td>['don', 't', 'let', 'app', 'that', 'are', 'lie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Does the Bible mention anything about a place ...</td>\n",
              "      <td>['does', 'the', 'bible', 'mention', 'anything'...</td>\n",
              "      <td>['doe', 'the', 'bibl', 'mention', 'anyth', 'ab...</td>\n",
              "      <td>['doe', 'bibl', 'mention', 'anyth', 'place', '...</td>\n",
              "      <td>St. John in the book of Revelation mentions an...</td>\n",
              "      <td>['st', 'john', 'in', 'the', 'book', 'of', 'rev...</td>\n",
              "      <td>['st', 'john', 'in', 'the', 'book', 'of', 'rev...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2fa7c73f-c30d-4d9b-bd6d-defa841a034e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2fa7c73f-c30d-4d9b-bd6d-defa841a034e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2fa7c73f-c30d-4d9b-bd6d-defa841a034e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a29e477e-8a68-4586-ab2a-44ab66797840\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a29e477e-8a68-4586-ab2a-44ab66797840')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a29e477e-8a68-4586-ab2a-44ab66797840 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 56402,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3234,\n        \"samples\": [\n          \"Can humans implant chlorophyll in their DNA and obtain energy through photosynthesis without eating to survive?\",\n          \"Is the term \\\"illegal immigrant\\\" meant to apply to the person or the offense, similar to calling a convict a \\\"murderer\\\"?\",\n          \"How is the postgraduate hostel at AIIMS Bhubaneswar?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokenized_question\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3234,\n        \"samples\": [\n          \"['can', 'humans', 'implant', 'chlorophyll', 'in', 'their', 'dna', 'and', 'obtain', 'energy', 'through', 'photosynthesis', 'without', 'eating', 'to', 'survive']\",\n          \"['is', 'the', 'term', 'illegal', 'immigrant', 'meant', 'to', 'apply', 'to', 'the', 'person', 'or', 'the', 'offense', 'similar', 'to', 'calling', 'a', 'convict', 'a', 'murderer']\",\n          \"['how', 'is', 'the', 'postgraduate', 'hostel', 'at', 'aiims', 'bhubaneswar']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stemmed_question\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3234,\n        \"samples\": [\n          \"['can', 'human', 'implant', 'chlorophyl', 'in', 'their', 'dna', 'and', 'obtain', 'energi', 'through', 'photosynthesi', 'without', 'eat', 'to', 'surviv']\",\n          \"['is', 'the', 'term', 'illeg', 'immigr', 'meant', 'to', 'appli', 'to', 'the', 'person', 'or', 'the', 'offens', 'similar', 'to', 'call', 'a', 'convict', 'a', 'murder']\",\n          \"['how', 'is', 'the', 'postgradu', 'hostel', 'at', 'aiim', 'bhubaneswar']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"setmmed_nostop_answer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3234,\n        \"samples\": [\n          \"['human', 'implant', 'chlorophyl', 'dna', 'obtain', 'energi', 'photosynthesi', 'without', 'eat', 'surviv']\",\n          \"['term', 'illeg', 'immigr', 'meant', 'appli', 'person', 'offens', 'similar', 'call', 'convict', 'murder']\",\n          \"['postgradu', 'hostel', 'aiim', 'bhubaneswar']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 54726,\n        \"samples\": [\n          \"It depends very much upon the type of private school and the location and funding available for the public schools. Some local religious based private schools are unable to compete for the most talented and experienced teachers.\\n There are public schools that compare favorably to many private schools but they are rare.\\n i was in private schools through college and at each stage the quality of education improved. My daughters had spectacular public educations through university in award winning systems. My son graduated from a top private university and was fully prepared for the challenge by the public system he attended through high school.\\n The rare elite public systems are also generally attended by peers who resemble those in private schools.\\n\",\n          \"Milk tea, known as chai in our culture and country, with a paratha with omlette. The paratha is a scrumptious substitute for tortillas or pita bread. We have more variety as well, such as halwa and poori, i hope you know what this is : )\\n\",\n          \"Probably tobirama. He probably knows best how to counter stuff like tsukoyomi due to his (kinda) hatered of the uchiha. He is equal to madaras brother, who is as strong as madara. And madara should be stronger than itachi since itachi wasn\\u2019t in a war for most of his life so he doesn\\u2019t have the experince or instinct\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokenized_answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 54535,\n        \"samples\": [\n          \"['participate', 'in', 'the', 'event', 'win', 'exciting', 'prizes', 'and', 'make', 'your', 'child', 'a', 'super', 'star', 'please', 'visit', 'cudokid', 'fb', 'page', 'for', 'more', 'details', 'please', 'share', 'like', 'and', 'follow', 'for', 'more', 'updates', 'and', 'exciting', 'events', 'a', 'community', 'of', 'parents', 'to', 'know', 'be', 'updated', 'and', 'to', 'share', 'the', 'new', 'ideas', 'about', 'parenting', 'our', 'page', 'intends', 'to', 'keep', 'parents', 'updated', 'about', 'the', 'kids', 'world', 'follow', 'us', 'to', 'learn', 'how', 'to', 'add', 'fun', 'to', 'parenting', 'fb', 'link', 'linked', 'text', 'cudokid', 'url', 'https', 'www', 'facebook', 'com', 'cudokid', '105257111152133']\",\n          \"['well', 'if', 'those', 'are', 'the', 'choices', 'i\\u2019m', 'for', 'netflix', 'and', 'chill', 'but', '\\u2026', 'what', 'about', 'a', 'nice', 'slow', 'dinner', 'and', 'then', 'reading', 'and', 'talking', 'until', 'bedtime']\",\n          \"['there', 'are', 'many', 'excellent', 'security', 'tools', 'that', 'are', 'available', 'for', 'free', 'and', 'even', 'more', 'that', 'are', 'expensive', 'but', 'free', 'for', 'non', 'commercial', 'use', 'but', 'i', 'am', 'unaware', 'of', 'anyone', 'setting', 'up', 'a', 'company', 'to', 'better', 'market', 'and', 'distribute', 'these', 'because', 'it', 'would', 'be', 'very', 'hard', 'for', 'such', 'an', 'operation', 'to', 'cover', 'its', 'costs']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stemmed_answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 54524,\n        \"samples\": [\n          \"['in', 'england', 'peopl', 'speak', 'english', 'the', 'languag', 'is', 'name', 'after', 'the', 'countri', 'in', 'wale', 'some', 'peopl', 'speak', 'welsh', 'the', 'nativ', 'languag', 'but', 'the', 'major', 'speak', 'english', 'in', 'scotland', 'and', 'northern', 'ireland', 'some', 'peopl', 'speak', 'gaelic', 'the', 'nativ', 'languag', 'but', 'the', 'major', 'speak', 'english', 'in', 'the', 'usa', 'some', 'peopl', 'use', 'nativ', 'american', 'languag', 'but', 'the', 'major', 'speak', 'english', 'there', 'is', 'also', 'a', 'special', 'breed', 'of', 'american', 'who', 'feel', 'that', 'they', 'speak', 'english', 'better', 'than', 'the', 'english', 'do', 'those', 'peopl', 'are', 'known', 'as', 'cunt']\",\n          \"['i', 'don', 't', 'want', 'to', 'give', 'a', 'figur', 'for', 'maximum', 'packag', 'becaus', 'it', 'depend', 'on', 'the', 'compani', 'and', 'the', 'profil', 'you', 'choos', 'but', 'the', 'minimum', 'would', 'be', 'around', '3', 'to', '3', '5', 'lpa', 'in', 'a', 'r', 'd', 'sector', 'there', 'are', 'chanc', 'of', 'get', 'even', 'more', 'in', 'a', 'r', 'd', 'again', 'base', 'on', 'the', 'compani', 'and', 'the', 'profil', 'you', 'would', 'be', 'go', 'to', 'but', 'if', 'you', 'need', 'an', 'estim', 'of', 'maximum', 'packag', 'it', 'would', 'be', 'lie', 'around', '5', '5', 'to', '6', '5', 'lpa', 'in', 'r', 'd', 'and', 'it', 'associ', 'sector']\",\n          \"['the', 'length', 'of', 'train', '500', 'ft', 'the', 'length', 'of', 'tunnel', '500', 'ft', 'the', 'total', 'distanc', 'train', 'ha', 'to', 'travel', '500', '500', '1000ft', 'the', 'speed', 'of', 'the', 'train', '500', 'ft', 'min', 'the', 'time', 'requir', 'distanc', 'in', 'ft', 'speed', 'ft', 'min', 'min', '1000ft', '500ft', 'min', '2', 'min']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test & Train Split\n",
        "df = df.sample(frac=1)\n",
        "\n",
        "# Ratio and index definition\n",
        "ratio = 0.75\n",
        "total_rows = df.shape[0]\n",
        "train_size = int(total_rows*ratio)\n",
        "\n",
        "# Split data into test and train\n",
        "train = df[0:train_size]\n",
        "test = df[train_size:]"
      ],
      "metadata": {
        "id": "w5Qmv9SnPos2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tokenizer and model\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "\n",
        "# Prepare dataset and dataloader\n",
        "train_dataset = T5Dataset(df, tokenizer)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/content/gdrive/My Drive/Indigo-HackToHire/T5results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,\n",
        "    warmup_steps=10,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='/content/gdrive/My Drive/Indigo-HackToHire/logs',\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pVvseAg7PzG6",
        "outputId": "71ad1818-876c-43f4-f2c0-07f957829fa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='17986' max='84603' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [17986/84603 36:19 < 2:14:32, 8.25 it/s, Epoch 0.64/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.377600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.023700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.013300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.007900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.008200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.006700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.002700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.002800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.002400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.002200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.001300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.001600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>0.001800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15500</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16500</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17500</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25832' max='84603' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25832/84603 52:01 < 1:58:21, 8.28 it/s, Epoch 0.92/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.377600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.023700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.013300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.007900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.008200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.006700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.002700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.002800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.002400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.002200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.001300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>0.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.001600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>0.001800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15500</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16500</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17500</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18000</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18500</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19000</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19500</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20000</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20500</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21000</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21500</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22000</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22500</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23000</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23500</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24000</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24500</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25000</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25500</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save_pretrained('/content/gdrive/My Drive/Indigo-HackToHire/t5_model')\n",
        "tokenizer.save_pretrained('/content/gdrive/My Drive/Indigo-HackToHire/t5_model')"
      ],
      "metadata": {
        "id": "7DizEbhyqKQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(model, tokenizer, question, device='cuda'):\n",
        "    inputs = tokenizer.encode_plus(question, return_tensors='pt').to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs.input_ids[0]))\n",
        "    return answer\n",
        "\n",
        "def compute_metrics(references, predictions):\n",
        "    bleu_scores = []\n",
        "    rouge_l_scores = []\n",
        "    f1_scores = []\n",
        "\n",
        "    rouge = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "\n",
        "    for ref, pred in zip(references, predictions):\n",
        "        # BLEU score\n",
        "        bleu_score = sentence_bleu([ref.split()], pred.split())\n",
        "        bleu_scores.append(bleu_score)\n",
        "\n",
        "        # ROUGE-L score\n",
        "        rouge_l_score = rouge.score(ref, pred)['rougeL'].fmeasure\n",
        "        rouge_l_scores.append(rouge_l_score)\n",
        "\n",
        "        # F1-score\n",
        "        ref_tokens = set(ref.split())\n",
        "        pred_tokens = set(pred.split())\n",
        "        common_tokens = ref_tokens.intersection(pred_tokens)\n",
        "\n",
        "        if len(common_tokens) == 0:\n",
        "            f1 = 0.0\n",
        "        else:\n",
        "            precision = len(common_tokens) / len(pred_tokens)\n",
        "            recall = len(common_tokens) / len(ref_tokens)\n",
        "            f1 = 2 * (precision * recall) / (precision + recall)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
        "    avg_rouge_l = sum(rouge_l_scores) / len(rouge_l_scores)\n",
        "    avg_f1 = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "    return avg_bleu, avg_rouge_l, avg_f1\n",
        "\n",
        "# Example usage\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "\n",
        "questions = test.question\n",
        "references = test.answer\n",
        "\n",
        "predictions = [generate_answer(model, tokenizer, q, device) for q in questions]\n",
        "\n",
        "avg_bleu, avg_rouge_l, avg_f1 = compute_metrics(references, predictions)\n",
        "\n",
        "print(f\"Average BLEU Score: {avg_bleu}\")\n",
        "print(f\"Average ROUGE-L Score: {avg_rouge_l}\")\n",
        "print(f\"Average F1 Score: {avg_f1}\")"
      ],
      "metadata": {
        "id": "KBScrRpnx_gr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}